{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656bd16b",
   "metadata": {},
   "source": [
    "# 20 October 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5422b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4f959ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "p\n",
      "p\n",
      "l\n",
      "e\n",
      "_____________\n",
      "\n",
      "A\n",
      "B\n",
      "\n",
      "\n",
      "Ford\n",
      "Mustang\n",
      "1964\n"
     ]
    }
   ],
   "source": [
    "for x in \"Apple\":\n",
    "    print(x)\n",
    "\n",
    "print(\"_____________\")\n",
    "print()\n",
    "\n",
    "for x in [\"A\", \"B\"]:\n",
    "    print(x)\n",
    "    \n",
    "print()\n",
    "print()\n",
    "thisdict =\t{\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "for x in thisdict:\n",
    "  print(thisdict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28e35a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test']\n",
      "<Text: This is a test...>\n"
     ]
    }
   ],
   "source": [
    "t = word_tokenize(\"This is a test\")\n",
    "print(t) # ['This', 'is', 'a', 'test']\n",
    "\n",
    "\n",
    "print(nltk.Text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da2833f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'test']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"A test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cec0a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 3 samples and 7 outcomes>\n",
      "<FreqDist with 3 samples and 7 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# Frequency\n",
    "\n",
    "t = FreqDist([\"Hello\", \"Hello\", \"Test\", \"Hi\", \"Hi\", \"Hi\", \"Hi\"])\n",
    "t\n",
    "print(t)\n",
    "\n",
    "\n",
    "a = FreqDist([\"Hello\", \"Hello\", \"Test\", \"Hi\", \"Hi\", \"Hi\", \"Hi\"])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7c41eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discov\n",
      "discov\n"
     ]
    }
   ],
   "source": [
    "# Stemming is a text processing task in which you reduce words to their root,\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "t = stemmer.stem(\"Running\")\n",
    "t = stemmer.stem(\"Helped\")\n",
    "t = stemmer.stem(\"Discovered\")\n",
    "print(t)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e8798",
   "metadata": {},
   "source": [
    "Lemmatization and Stemming, both are used to generate root form of derived (inflected) words. However, lemma is an actual language word, whereas stem may not be an actual word.\n",
    "\n",
    "Lemmatization considers the context and converts the word to its meaningful base form, which is called Lemma.\n",
    "Lemmatization is computationally expensive since it involves look-up tables and what not.\n",
    "\n",
    "Stemming is used in case of large dataset where performance is an issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1c67086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "Caring : Caring\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "print(\"Caring :\", lemmatizer.lemmatize(\"Caring\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6dbf24a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "moby = Text([\"Hi\", \"Hi\", \"A\"])\n",
    "moby.count(\"Aa\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ade6a66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Cat'], dtype='<U3'), array(['Cat'], dtype='<U3'), array(['Dog'], dtype='<U3')]\n",
      "(array(['Cat', 'Cow', 'Dog'], dtype='<U3'), array([0, 2, 1, 2])) ____________ unique_results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m____________ unique_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m unique_results:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(unique_results[x], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Unique words\n",
    "\n",
    "t = [\"Cat\", \"Cat\", \"Dog\"]\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "unique_vocabularies = []\n",
    "\n",
    "for k in range(len(t)):\n",
    "    temptext = t[k]\n",
    "\n",
    "    unique_results = np.unique(temptext, return_inverse=True)\n",
    "    unique_words = unique_results[0]\n",
    " \n",
    "    unique_vocabularies.append(unique_words)\n",
    "    \n",
    "\n",
    "print(unique_vocabularies)\n",
    "\n",
    "for x in unique_vocabularies:\n",
    "    x\n",
    "    \n",
    "    \n",
    "unique_results = np.unique([\"Cat\", \"Dog\", \"Cow\", \"Dog\"], return_inverse=True)\n",
    "\n",
    "\n",
    "print(unique_results, '____________ unique_results')\n",
    "\n",
    "for x in unique_results:\n",
    "    print(unique_results[x], '20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d49dc4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: C a t...>\n",
      "<Text: D o g...>\n",
      "<Text: C o w...>\n",
      "<Text: D o g...>\n",
      "['Cat' 'Cow' 'Dog']\n",
      "[0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "unique_results = np.unique([\"Cat\", \"Dog\", \"Cow\", \"Dog\"], return_inverse=True)\n",
    "\n",
    "\n",
    "t = [\"Cat\", \"Dog\", \"Cow\", \"Dog\"]\n",
    "\n",
    "tt = []\n",
    "\n",
    "\n",
    "for x in t:\n",
    "    tt.append(nltk.Text(x))\n",
    "\n",
    "    \n",
    "for x in tt:\n",
    "    print(x)\n",
    "    \n",
    "unique_results = np.unique(t, return_inverse=True)\n",
    "unique_results\n",
    "\n",
    "\n",
    "\n",
    "for x in unique_results:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e61911f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(a, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(indices[x])\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "a = np.array(['a', 'b', 'b', 'c', 'a'])\n",
    "indices = np.unique(a, return_index=True)\n",
    "for x in indices:\n",
    "    print(indices[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
